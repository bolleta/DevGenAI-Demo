{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc40c48b-0c95-4757-a067-563cfccd51a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amazon Bedrock を AWS SDK for Python (boto3) から使用する基本的なサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5a54a-fa41-426c-8430-ce5ee22df9a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** このノートブックは、SageMaker Studioの **Data Science 3.0** カーネルで動作します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f05d4-4962-4238-8a38-5aaaa9ce9161",
   "metadata": {
    "tags": []
   },
   "source": [
    "### モデルの情報の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4d6b8-dd50-4a1c-9556-d0960a536419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "\n",
    "bedrock = boto3.client(\"bedrock\", region_name=\"us-east-1\")\n",
    "pprint.pprint(bedrock.list_foundation_models()[\"modelSummaries\"])\n",
    "print(\"-\" * 80)\n",
    "pprint.pprint(bedrock.get_foundation_model(modelIdentifier = \"amazon.titan-text-express-v1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d8eab-f1cc-4029-94e5-5072a41221d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### テキスト生成\n",
    "参考：[モデル呼び出し API を使用して Amazon Bedrock で Meta Llama 3 を呼び出す | Amazon Bedrockユーザーガイド](https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModel_MetaLlama3_section.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298abcf-ca20-48b4-902a-9f96025d0515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client('bedrock-runtime')\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "modelId = \"meta.llama3-8b-instruct-v1:0\"\n",
    "\n",
    "prompt = \"日本の首都はどこですか？簡潔に日本語で回答してください。\"\n",
    "\n",
    "formatted_prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# リクエストBODYの指定\n",
    "body = json.dumps({\n",
    "    \"prompt\": formatted_prompt,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.1,\n",
    "    \"max_gen_len\": 100\n",
    "})\n",
    "\n",
    "\n",
    "response = bedrock.invoke_model(body=body,\n",
    "                                modelId=modelId,\n",
    "                                accept=accept, \n",
    "                                contentType=contentType)\n",
    "\n",
    "# API レスポンスから BODY を取り出す\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# レスポンスBODYから応答テキストを取り出す\n",
    "\n",
    "#print(response_body)\n",
    "\n",
    "outputText = response_body.get('generation')\n",
    "\n",
    "\n",
    "print(outputText)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d0df8-768e-40d6-a1e3-e00ccdc64ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### テキスト要約\n",
    "参考：[モデル呼び出し API を使用して Amazon Bedrock で Meta Llama 3 を呼び出す | Amazon Bedrockユーザーガイド](https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModel_MetaLlama3_section.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1c26b-54e5-4f1f-b98f-8fee35559628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "\n",
    "下記のテキストの要約を日本語で提示して下さい。\n",
    "<text>\n",
    "AWS はお客様からのフィードバックをすべて取り入れ、本日 Amazon Bedrock を発表できることを嬉しく思います。\\\n",
    "AI21 Labs、Anthropic、Stability AI、Amazon の FM に API 経由でアクセスできるようにする新しいサービスです。 \\\n",
    "Bedrock は、顧客が FM を使用して生成 AI ベースのアプリケーションを構築および拡張する最も簡単な方法です。\\\n",
    "すべての建設業者のアクセスを民主化します。 Bedrock は、さまざまな強力な FM にアクセスする機能を提供します。\n",
    "テキストと画像用 -  同じく発表している 2 つの新しい LLM で構成される Amazons Titan FM を含む \\\n",
    "今日、スケーラブルで信頼性が高く安全な AWS マネージド サービスを通じて。 Bedrock のサーバーレス エクスペリエンスにより、\\\n",
    "顧客は、やろうとしていることに適したモデルを簡単に見つけて、非公開ですぐに開始できます \\\n",
    "FM を独自のデータでカスタマイズし、AWS を使用してアプリケーションに簡単に統合してデプロイできます。\\\n",
    "インフラストラクチャ を管理する必要がなく、使い慣れたツールや機能を利用できます。\\\n",
    "(統合を含むさまざまなモデルをテストするための実験や、大規模な FM を管理するためのパイプラインなどの Amazon SageMaker ML 機能を使用します)。\n",
    "</text>\n",
    "\"\"\"\n",
    "\n",
    "formatted_prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": formatted_prompt,\n",
    "                 \"max_gen_len\": 512,\n",
    "                 \"temperature\":0.5,\n",
    "                 \"top_p\":0.5\n",
    "                  }) \n",
    "                  \n",
    "\n",
    "modelId = \"meta.llama3-8b-instruct-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = boto3_bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "outputText = response_body.get('generation')\n",
    "\n",
    "\n",
    "print(outputText)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd34cae-38ac-481e-a77e-520ec64a3bdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ストリーム出力\n",
    "参考：[レスポンスストリームで Invoke Model API を使用して Amazon Bedrock で Meta Llama 3 を呼び出す | Amazon Bedrockユーザーガイド](https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModelWithResponseStream_MetaLlama3_section.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50789f5c-65ab-4479-a0ac-25f7f8bbae60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "prompt = \"\"\"\n",
    "AWS とは何かを簡単に日本語で説明してください。\n",
    "\"\"\"\n",
    "\n",
    "formatted_prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": formatted_prompt,\n",
    "                 \"max_gen_len\": 512,\n",
    "                 \"temperature\":0.5,\n",
    "                 \"top_p\":0.5\n",
    "                  }) \n",
    "\n",
    "\n",
    "modelId = \"meta.llama3-8b-instruct-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "\n",
    "# 1. Extract and print the response text with number\n",
    "# stream = response.get('body')\n",
    "# count = 0\n",
    "# if stream:\n",
    "#     for event in stream:\n",
    "#         chunk = event.get('chunk')\n",
    "#         if chunk:\n",
    "#            chunk_bytes = chunk.get('bytes').decode()\n",
    "#            result = json.loads(chunk_bytes)\n",
    "#            count +=1\n",
    "#            print(f'[{count}] {result[\"generation\"]}')\n",
    "            \n",
    "\n",
    "# 2. Extract and print the response text in real-time.\n",
    "for event in response[\"body\"]:\n",
    "    chunk = json.loads(event[\"chunk\"][\"bytes\"])\n",
    "    if \"generation\" in chunk:\n",
    "        print(chunk[\"generation\"], end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64664ee-86c8-49fa-92fb-6b0b32610f77",
   "metadata": {},
   "source": [
    "### 課題\n",
    "下記のサンプルと同じプロンプトを使用して、Mistral Large (24.02) モデルに対して invokeModel を発行するコードを完成させてみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57597a3d-a71d-4d33-b9ed-d899008ea653",
   "metadata": {},
   "source": [
    "#### Amazon Titan Text G1 Express のサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68bddd-9ba4-43a0-b1d2-418c42d2deac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "#\n",
    "# Amazon Titan Text G1 Express\n",
    "#\n",
    "print(\"---\" * 42)\n",
    "print(\"Amazon Titan Text G1 Express\")\n",
    "print(\"---\" * 42)\n",
    "\n",
    "\n",
    "try:\n",
    "    bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "    prompt_data = \"\"\"Describe the purpose of a 'hello world' program in one line.\"\"\"\n",
    "    config = {\"maxTokenCount\": 512, \"temperature\": 0.5, \"topP\": 0.9 }\n",
    "\n",
    "    body = json.dumps(\n",
    "            {\n",
    "                \"inputText\": prompt_data, \"textGenerationConfig\": config\n",
    "            }\n",
    "    )\n",
    "    modelId = \"amazon.titan-text-express-v1\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    print(response_body.get(\"results\")[0].get(\"outputText\"))\n",
    "\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e7ad0-4e6f-48cd-a267-dff628cb8a07",
   "metadata": {},
   "source": [
    "#### Meta Llama 3 8B Instruct のサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d79e06-89d8-4c08-93ba-7d198081e88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#\n",
    "# Meta Llama 3 8B Instruct\n",
    "#\n",
    "print(\"---\" * 42)\n",
    "print(\"Meta Llama 3 8B Instruct\")\n",
    "print(\"---\" * 42)\n",
    "\n",
    "\n",
    "try:\n",
    "    bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "    prompt_data = \"\"\"Describe the purpose of a 'hello world' program in one line.\"\"\"\n",
    "    max_gen_len = 512\n",
    "    temperature = 0.5\n",
    "    top_p = 0.9\n",
    "\n",
    "    body =json.dumps(\n",
    "        {\n",
    "            \"prompt\": prompt_data, \"max_gen_len\": max_gen_len, \"temperature\": temperature, \"top_p\": top_p\n",
    "        }\n",
    "    )\n",
    "    modelId = \"meta.llama3-8b-instruct-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "    print(response_body[\"generation\"])\n",
    "\n",
    "except ClientError as error:\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcfa39-e49b-4d75-9ecd-496cb12135a2",
   "metadata": {},
   "source": [
    "#### Mistral Large (24.02) を使用するコードを下のセルに記述してみましょう\n",
    "\n",
    "* ヒント 1： AWS マネジメントコンソールの Amazon Bedrock のページの左側メニューで「プロバイダー」を選択し、Mistral AI のタブから使用するモデルの API のパラメータを確認しましょう\n",
    "* ヒント 2: レスポンスの受け取り方については、[このドキュメント](https://docs.aws.amazon.com/ja_jp/bedrock/latest/userguide/bedrock-runtime_example_bedrock-runtime_InvokeModel_MistralAi_section.html)　を参考にしましょう　  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4607ff82-8342-4ca6-ada7-0196b52c61ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:338448213940:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
