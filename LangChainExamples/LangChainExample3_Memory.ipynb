{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60414fc-0733-42b6-9fac-633990683e25",
   "metadata": {},
   "source": [
    "# LangChain サンプル 3: Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799faf1c-8408-4d39-8790-0b6b1faf0bee",
   "metadata": {},
   "source": [
    "<i aria-hidden=\"true\" class=\"fas fa-sticky-note\" style=\"color:#563377\"></i> **Note:** このノートブックは、SageMaker Studioの **Data Science 3.0** カーネルで動作します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5008fc-f5f1-4c8a-995e-a893186df9ce",
   "metadata": {},
   "source": [
    "### LangChain の Memory を使わない生成 AI のチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8db39-592c-4471-9843-cdae0837a2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock                   \n",
    "from langchain_core.messages.human import HumanMessage \n",
    "\n",
    "chat = ChatBedrock(\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\" \n",
    ")\n",
    "\n",
    "print(\"私は LangChain の Memory モジュールを使わないチャットボットです。メッセージを入力してください。\\n\")\n",
    "\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    prompt = input(\"prompt>\")\n",
    "    \n",
    "    if prompt == \"quit\":\n",
    "        flag = False\n",
    "    else:\n",
    "        result = chat.invoke( # Chat modelsを使ってモデルを呼び出す\n",
    "            [\n",
    "              HumanMessage(content = prompt) \n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # レスポンスを表示\n",
    "        print(\"response> \" + result.content)\n",
    "        \n",
    "print(\"チャットボットを終了しました。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9fae9-f3dd-4b45-95e4-1d87014bdb11",
   "metadata": {},
   "source": [
    "###  LangChain の Memory を使った生成 AI のチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0599a-c4b7-4f13-ad71-285a92b43586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock                   \n",
    "from langchain.memory.buffer import ConversationBufferMemory  \n",
    "from langchain_core.messages.human import HumanMessage    \n",
    "\n",
    "chat = ChatBedrock(\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\" \n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory( # メモリを初期化\n",
    "    return_messages = True\n",
    ")\n",
    "\n",
    "print(\"私は LangChain の ConversationBufferMemory を使っているチャットボットです。メッセージを入力してください。\\n\")\n",
    "\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    prompt = input(\"prompt>\")\n",
    "    \n",
    "    if prompt == \"quit\":\n",
    "        flag = False\n",
    "    else:\n",
    "        memory_message_result = memory.load_memory_variables({}) # メモリの内容を取得\n",
    "        messages = memory_message_result['history'] # メモリの内容からメッセージのみを取得\n",
    "        messages.append(HumanMessage(content=prompt)) # ユーザーからのメッセージを追加\n",
    "\n",
    "        result = chat.invoke( # Chat modelsを使ってモデルを呼び出す\n",
    "            messages\n",
    "        )\n",
    "        \n",
    "        memory.save_context(  # メモリにメッセージを追加\n",
    "            {\n",
    "                \"input\": prompt,  # ユーザーからのメッセージをinputとして保存\n",
    "            },\n",
    "            {\n",
    "                \"output\": result.content,  # AIからのメッセージをoutputとして保存\n",
    "            }\n",
    "        )\n",
    "        # レスポンスを表示\n",
    "        print(\"response> \" + result.content)\n",
    "        \n",
    "print(\"チャットボットを終了しました。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfab918-2909-4cdc-9037-029c2bd6d5f9",
   "metadata": {},
   "source": [
    "###  LangChain の ConversationChain を使った生成 AI のチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f2f27-06b9-4607-9f8e-da25a56644a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.base import ConversationChain  \n",
    "from langchain_aws import ChatBedrock                   \n",
    "from langchain.memory.buffer import ConversationBufferMemory  \n",
    "from langchain_core.messages.human import HumanMessage    \n",
    "\n",
    "chat = ChatBedrock(\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\" \n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory( \n",
    "    return_messages = True\n",
    ")\n",
    "\n",
    "chain = ConversationChain( # ConversationChainを初期化\n",
    "    memory = memory,\n",
    "    llm = chat,\n",
    ")\n",
    "\n",
    "print(\"私は LangChain の ConversationChain を使っているチャットボットです。メッセージを入力してください。\\n\")\n",
    "\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    prompt = input(\"prompt>\")\n",
    "    \n",
    "    if prompt == \"quit\":\n",
    "        flag = False\n",
    "    else:\n",
    "        result = chain.invoke(prompt)\n",
    "        # レスポンスを表示\n",
    "        print(\"response> \" + result[\"response\"])\n",
    "print(\"チャットボットを終了しました。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4ec69-dca6-42f6-87f5-047411d4e845",
   "metadata": {},
   "source": [
    "###  LangChain の ConversationBufferWindowMemory を使った生成 AI のチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed721c2-0f47-47ca-a5c7-1a87476ff05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory.buffer_window import ConversationBufferWindowMemory \n",
    "from langchain.chains.conversation.base import ConversationChain  \n",
    "from langchain_aws import ChatBedrock                   \n",
    "from langchain_core.messages.human import HumanMessage    \n",
    "\n",
    "chat = ChatBedrock(\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\" \n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages = True,\n",
    "    k = 3 # 3往復分のメッセージを記憶\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat\n",
    ")\n",
    "\n",
    "print(\"私は LangChain の ConversationBufferWindowMemory を使っているチャットボットです。メッセージを入力してください。\\n\")\n",
    "\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    prompt = input(\"prompt>\")\n",
    "    \n",
    "    if prompt == \"quit\":\n",
    "        flag = False\n",
    "    else:\n",
    "        messages = chain.memory.load_memory_variables({})[\"history\"] # 保存されているメッセージを取得\n",
    "        print(f\"--- 保存されているメッセージの数: {len(messages)} ---\") # 保存されているメッセージ数を表示\n",
    "\n",
    "        for saved_message in messages: # 保存されているメッセージを1つずつ取り出す\n",
    "            print(saved_message.content) # 保存されているメッセージを表示する\n",
    "        print(\"---\" * 10) \n",
    "\n",
    "        result = chain.invoke(prompt)\n",
    "        # レスポンスを表示\n",
    "        print(result[\"response\"])\n",
    "        \n",
    "print(\"チャットボットを終了しました。\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad93141-cab6-45f1-b46a-eb08d4688327",
   "metadata": {},
   "source": [
    "###  LangChain の ConversationSummaryMemory を使った生成 AI のチャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a22f0-9a13-452e-b3aa-c7545e22c85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.base import ConversationChain  \n",
    "from langchain_aws import ChatBedrock                           \n",
    "from langchain.memory.summary import ConversationSummaryMemory  \n",
    "from langchain_core.messages.human import HumanMessage    \n",
    "from langchain_core.messages.system import SystemMessage  \n",
    "\n",
    "\n",
    "chat = ChatBedrock(\n",
    "    model_id = \"meta.llama3-8b-instruct-v1:0\" \n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(  # ConversationSummaryMemoryを使用するように変更\n",
    "    llm=chat,  # Chat modelsを指定\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "print(\"私は LangChain の ConversationBufferWindowMemory を使っているチャットボットです。メッセージを入力してください。\\n\")\n",
    "\n",
    "flag = True\n",
    "\n",
    "while flag:\n",
    "    prompt = input(\"prompt>\")\n",
    "    \n",
    "    if prompt == \"quit\":\n",
    "        flag = False\n",
    "    else:\n",
    "        messages = chain.memory.load_memory_variables({})[\"history\"] # 保存されているメッセージを取得\n",
    "\n",
    "        print(f\"--- 保存されているメッセージの数: {len(messages)} ---\") # 保存されているメッセージの数を表示\n",
    "        for saved_message in messages: # 保存されているメッセージを1つずつ取り出す\n",
    "            print(saved_message.content) # 保存されているメッセージを表示する\n",
    "        print(\"---\" * 10) \n",
    "\n",
    "        result = chain.invoke(prompt)\n",
    "        # レスポンスを表示\n",
    "        print(result[\"response\"])\n",
    "        \n",
    "print(\"チャットボットを終了しました。\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cdf3d3-302c-491c-be5e-6db0a81951e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:887800404361:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
